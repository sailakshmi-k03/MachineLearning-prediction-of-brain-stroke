1)# Importing the libraries

import pandas as pd
import numpy as np 
import matplotlib.pyplot as plt
import seaborn as sns
# Ignore harmless warnings 
import warnings 
warnings.filterwarnings("ignore")
# Set to display all the columns in dataset
pd.set_option("display.max_columns", None)

2)# Import psql to run queries 
import pandasql as psql


3)# load the brain stroke data

brain_stroke=pd.read_csv('../input/full-filled-brain-stroke-dataset/full_data.csv')

# creating back_up file

brain_stroke_bk=brain_stroke.copy()

4)# Displaying the first 5 rows

brain_stroke.head()

5)Graphs:
#Grouping People by work type
plt.figure(figsize=(16,8))
sns.set_style("whitegrid")
plt.title('Grouping People by work type', fontsize=30, fontweight='bold', y=1.05,)
plt.xlabel('work_type',fontsize=25)
plt.ylabel('Count',fontsize=25)
sns.countplot(x="work_type", data=brain_stroke, palette="hls");
plt.show()

#Grouping People by their gender
plt.figure(figsize=(16,8))
sns.set_style("whitegrid")
plt.title('Grouping People by their gender', fontsize=30, fontweight='bold', y=1.05,)
plt.xlabel('gender',fontsize=25)
plt.ylabel('Count',fontsize=25)
sns.countplot(x="gender", data=brain_stroke, palette="hls");
plt.show()

#Grouping People by their Residence_type
plt.figure(figsize=(16,8))
sns.set_style("whitegrid")
plt.title('Grouping People by their Residence_type', fontsize=30, fontweight='bold', y=1.05,)
plt.xlabel('Residence_type',fontsize=25)
plt.ylabel('Count',fontsize=25)
sns.countplot(x="Residence_type", data=brain_stroke, palette="hls");
plt.show()

#Grouping People by smokig_status
plt.figure(figsize=(16,8))
sns.set_style("whitegrid")
plt.title('Grouping People by smokig_status', fontsize=30, fontweight='bold', y=1.05,)
plt.xlabel('smoking_status',fontsize=25)
plt.ylabel('Count',fontsize=25)
sns.countplot(x="smoking_status", data=brain_stroke, palette="hls");
plt.show()

6)brain_stroke['work_type'].value_counts

#SNS Plots
sns.countplot(x='gender', data=brain_stroke, hue='stroke')

sns.countplot(x='ever_married', data=brain_stroke, hue='stroke')

sns.countplot(x='work_type', data=brain_stroke, hue='stroke')

sns.countplot(x='Residence_type', data=brain_stroke, hue='stroke')

sns.countplot(x='smoking_status', data=brain_stroke, hue='stroke')

sns.countplot(x='heart_disease', data=brain_stroke, hue='stroke')

7)#information of columns in data
brain_stroke.info()

8)#checking null values
brain_stroke.isnull().sum()

9)#checking for duplicates
brain_stroke.duplicated().any()

10)#if any keep them in last
brain_stroke_dup=brain_stroke[brain_stroke.duplicated(keep="last")]
brain_stroke_dup

11)#boxplot 
plt.figure(figsize=(10,7))
brain_stroke.boxplot()

12)# count the target or dependent variable by '0' , '1'  & their proportion(>= 10 : 1 , then the dataset is imbalance dataset)
brain_stroke_count=brain_stroke.stroke.value_counts()
print('class :0',brain_stroke_count[0])
print('class :1',brain_stroke_count[1])
print('proportion :',round(brain_stroke_count[0]/brain_stroke_count[1],2),':1')
print('Total stroke Records:',len(brain_stroke))


13)# Display the data by variables wise
for i in brain_stroke.columns:
    print(brain_stroke[i].value_counts())

14)# use label encoder to handle categorical data
from sklearn.preprocessing import LabelBinarizer
LB = LabelBinarizer()
brain_stroke['gender']=LB.fit_transform(brain_stroke['gender'])
brain_stroke['ever_married']=LB.fit_transform(brain_stroke['ever_married'])
brain_stroke['Residence_type']=LB.fit_transform(brain_stroke['Residence_type'])

15)# use label encoder to handle categorical data
from sklearn.preprocessing import LabelEncoder
LE = LabelEncoder()
brain_stroke['work_type']=LE.fit_transform(brain_stroke['work_type'])
brain_stroke['smoking_status']=LE.fit_transform(brain_stroke['smoking_status'])


16)# Identify the independent and Target variables

IndepVar = []
for col in brain_stroke.columns:
    if col != 'stroke':
        IndepVar.append(col)

TargetVar = 'stroke'

x = brain_stroke[IndepVar]
y = brain_stroke[TargetVar]

17)#veiwing target variable value counts
data = sns.countplot(x=TargetVar,data=brain_stroke)
print(brain_stroke[TargetVar].value_counts())

18)#count of stroke values0,1
x.shape, y.shape

19)# Random over sampling can be implemented by using RandomOverSampler class
from imblearn.over_sampling import RandomOverSampler
oversample=RandomOverSampler(sampling_strategy=0.15)
x_over,y_over=oversample.fit_resample(x,y)
print(x_over.shape)
print(y_over.shape)


20)# count the target or dependent variable by '0' , '1'  & their proportion(>= 10 : 1 , then the dataset is imbalance dataset)
brain_stroke_count=brain_stroke.stroke.value_counts()
print('class :0',brain_stroke_count[0])
print('class :1',brain_stroke_count[1])
print('proportion :',round(brain_stroke_count[0]/brain_stroke_count[1],2),':1')
print('Total stroke Records:',len(brain_stroke))

21)# Splitting the dataset into train and test data
from sklearn.model_selection import train_test_split 
x_train, x_test, y_train, y_test = train_test_split(x_over, y_over, test_size=0.3, random_state=42)
# Displaying the shape 
x_train.shape, x_test.shape, y_train.shape, y_test.shape

22)# Scaling the features by using MinMaxScaler

from sklearn.preprocessing import MinMaxScaler
mmscaler = MinMaxScaler(feature_range=(0, 1))
x_train[cols] = mmscaler.fit_transform(x_train[cols])
x_train = pd.DataFrame(x_train)
x_test[cols] = mmscaler.fit_transform(x_test[cols])
x_test = pd.DataFrame(x_test)

23) # Build the Calssification models and compare the results

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.ensemble import BaggingClassifier

from sklearn.ensemble import GradientBoostingClassifier
!pip install light
import lightgbm as lgb

# Create objects of classification algorithm with default hyper-parameters

ModelLR = LogisticRegression()
ModelDC = DecisionTreeClassifier()
ModelRF = RandomForestClassifier()
ModelET = ExtraTreesClassifier()
ModelKNN = KNeighborsClassifier(n_neighbors=5)
ModelSVM = SVC(probability=True)

modelBAG = BaggingClassifier(base_estimator=None, n_estimators=100, max_samples=1.0, max_features=1.0,
                             bootstrap=True, bootstrap_features=False, oob_score=False, warm_start=False,
                             n_jobs=None, random_state=None, verbose=0)

'''ModelGB = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=100, subsample=1.0, 
                                     criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, 
                                     min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0,
                                     min_impurity_split=None, init=None, random_state=None,
                                     max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False,
                                     validation_fraction=0.1, n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)'''
ModelLGB = lgb.LGBMClassifier()
ModelGNB = GaussianNB()

24)# Evalution matrix for all the algorithms

MM = [ModelLR, ModelDC, ModelRF, ModelET, ModelKNN, ModelSVM, modelBAG, ModelLGB, ModelGNB]
for models in MM:
    
    # Fit the model
    
    models.fit(x_train, y_train)
    
    # Prediction
    
    y_pred = models.predict(x_test)
    y_pred_prob = models.predict_proba(x_test)
    
    # Print the model name
    
    print('Model Name: ', models)
    
    # confusion matrix in sklearn

    from sklearn.metrics import confusion_matrix
    from sklearn.metrics import classification_report

    # actual values

    actual = y_test

    # predicted values

    predicted = y_pred

    # confusion matrix

    matrix = confusion_matrix(actual,predicted, labels=[1,0],sample_weight=None, normalize=None)
    print('Confusion matrix : \n', matrix)

    # outcome values order in sklearn

    tp, fn, fp, tn = confusion_matrix(actual,predicted,labels=[1,0]).reshape(-1)
    print('Outcome values : \n', tp, fn, fp, tn)

    # classification report for precision, recall f1-score and accuracy

    C_Report = classification_report(actual,predicted,labels=[1,0])

    print('Classification report : \n', C_Report)

    # calculating the metrics

    sensitivity = round(tp/(tp+fn), 3);
    specificity = round(tn/(tn+fp), 3);
    accuracy = round((tp+tn)/(tp+fp+tn+fn), 3);
    balanced_accuracy = round((sensitivity+specificity)/2, 3);
    
    precision = round(tp/(tp+fp), 3);
    f1Score = round((2*tp/(2*tp + fp + fn)), 3);

    # Matthews Correlation Coefficient (MCC). Range of values of MCC lie between -1 to +1. 
    # A model with a score of +1 is a perfect model and -1 is a poor model

    from math import sqrt

    mx = (tp+fp) * (tp+fn) * (tn+fp) * (tn+fn)
    MCC = round(((tp * tn) - (fp * fn)) / sqrt(mx), 3)

    print('Accuracy :', round(accuracy*100, 2),'%')
    print('Precision :', round(precision*100, 2),'%')
    print('Recall :', round(sensitivity*100,2), '%')
    print('F1 Score :', f1Score)
    print('Specificity or True Negative Rate :', round(specificity*100,2), '%'  )
    print('Balanced Accuracy :', round(balanced_accuracy*100, 2),'%')
    print('MCC :', MCC)

    # Area under ROC curve 

    from sklearn.metrics import roc_curve, roc_auc_score

    print('roc_auc_score:', round(roc_auc_score(actual, predicted), 3))
    
    # ROC Curve
    
    from sklearn.metrics import roc_auc_score
    from sklearn.metrics import roc_curve
    logit_roc_auc = roc_auc_score(actual, predicted)
    fpr, tpr, thresholds = roc_curve(actual, models.predict_proba(x_test)[:,1])
    plt.figure()
    # plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)
    plt.plot(fpr, tpr, label= 'Classification Model' % logit_roc_auc)
    plt.plot([0, 1], [0, 1],'r--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver operating characteristic')
    plt.legend(loc="lower right")
    plt.savefig('Log_ROC')
    plt.show()
    print('-----------------------------------------------------------------------------------------------------')
    #----------------------------------------------------------------------------------------------------------
    '''new_row =pd.DataFrame( {'Model Name' : models,
               'True_Positive' : tp, 
               'False_Negative' : fn, 
               'False_Positive' : fp,
               'True_Negative' : tn,
               'Accuracy' : accuracy,
               'Precision' : precision,
               'Recall' : sensitivity,
               'F1 Score' : f1Score,
               'Specificity' : specificity,
               'MCC':MCC,
               'ROC_AUC_Score':roc_auc_score(actual, predicted),
               'Balanced Accuracy':balanced_accuracy})
    EMResults = EMResults.append(new_row, ignore_index=True)
    #----------------------------------------------------------------------------------------------------------'''